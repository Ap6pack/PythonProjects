import requests
from bs4 import BeautifulSoup, SoupStrainer

url_file = input("Enter the path to the file containing URLs (one per line): ")
payload_file = input("Enter the path to the file containing payloads (one per line): ")
output_file = "results.txt"

# Load payloads from file
with open(payload_file, 'r') as pf:
    payloads = [line.strip() for line in pf.readlines()]

print("Fuzzing begins!")

with open(url_file, 'r') as f, open(output_file, 'a') as o:
    for url in f.readlines():
        url = url.strip()
        try:
            initial = requests.get(url)
            soup = BeautifulSoup(initial.text, 'html.parser')
            fields = soup.find_all('input')

            for field in fields:
                for payload in payloads:
                    data = {}
                    if field.has_attr('name'):
                        if field['name'].lower() == "submit":
                            data[field['name']] = "submit"
                        else:
                            data[field['name']] = payload

                    response = requests.post(url, data=data)
                    o.write("URL: " + url + "\n")
                    o.write("Payload: " + payload + "\n")
                    o.write("Response:\n" + response.text + "\n")
                    print("Fuzzing completed for URL:", url)

        except requests.exceptions.RequestException as e:
            print("Error occurred for URL:", url)
            print("Error message:", str(e))

print("Fuzzing has ended")
